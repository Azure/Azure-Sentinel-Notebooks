{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [ "# Guided Investigation - Anomaly Lookup\n", "\n", "__Notebook Version:__ 1.0<br>\n", "__Python Version:__ Python 3.6 - AzureML<br>\n", "__Required Packages:__ Azure-Sentinel-Utilities<br>\n", "__Platforms Supported:__  Azure Machine Learning Notebooks\n", "     \n", "__Data Source Required:__ Log Analytics tables \n", "    \n", "### Description\n", "Gain insights into the possible root cause of an alert by searching for related anomalies on the corresponding entities around the alert’s time. This notebook will provide valuable leads for an alert’s investigation, listing all suspicious increase in event counts or their properties around the time of the alert, and linking to the corresponding raw records in Log Analytics for the investigator to focus on and interpret.\n", "\n", "<font>You may need to select Python 3.6 - AzureML on Azure Machine Learning Notebooks.</font>\n", "\n", "## Table of Contents\n", "\n", "1. Initialize Azure Resource Management Clients\n", "2. Looking up for anomaly entities" ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [ "## 1. Initialize Azure Resource Management Clients" ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [ "# only run once\n", "!pip install --upgrade Azure-Sentinel-Utilities" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": { "logged": 1601512955568 }
      }
    },
    {
      "cell_type": "code",
      "source": [ "# Set variables from config.json\n", "from SentinelWidgets import WidgetViewHelper\n", "from SentinelUtils import ConfigReader\n", "tenant_id, subscription_id, resource_group, workspace_id, workspace_name  = ConfigReader.read_config_values('config.json');" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": { "logged": 1602003219579 }
      }
    },
    {
      "cell_type": "code",
      "source": [ "from azure.loganalytics import LogAnalyticsDataClient\n", "from azure.loganalytics.models import QueryBody\n", "from azure.mgmt.loganalytics import LogAnalyticsManagementClient\n", "import SentinelAzure\n", "from SentinelAnomalyLookup import AnomalyFinder, AnomalyLookupViewHelper\n", "\n", "from pandas.io.json import json_normalize\n", "import sys\n", "import timeit\n", "import datetime as dt\n", "import pandas as pd\n", "import copy\n", "from IPython.display import HTML" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": { "logged": 1602003221090 }
      }
    },
    {
      "cell_type": "code",
      "source": [ "# Authentication to Log Analytics\n", "from azure.common.client_factory import get_client_from_cli_profile\n", "from azure.common.credentials import get_azure_cli_credentials\n", "!az login --tenant $tenant_id\n", "la_client = get_client_from_cli_profile(LogAnalyticsManagementClient, subscription_id = subscription_id)\n", "la = SentinelAzure.azure_loganalytics_helper.LogAnalyticsHelper(la_client)\n", "creds, _ = get_azure_cli_credentials(resource=\"https://api.loganalytics.io\")\n", "la_data_client = LogAnalyticsDataClient(creds)" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": { "logged": 1602004739244 }
      }
    },
    {
      "cell_type": "markdown",
      "source": [ "## 2. Looking up for anomaly entities" ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [ "# Entity inputs\n", "import ipywidgets as widgets\n", "#DateTime format: 2019-07-15T07:05:20.000\n", "q_timestamp = widgets.Text(value='2020-10-06',description='DateTime: ')\n", "display(q_timestamp)\n", "#Entity format: computer\n", "q_entity = widgets.Text(value='user',description='Entity: ')\n", "display(q_entity)" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": { "logged": 1602004761963 }
      }
    },
    {
      "cell_type": "code",
      "source": [ "# Select tables\n", "import warnings\n", "warnings.simplefilter(action='ignore', category=FutureWarning)\n", "anomaly_lookup = AnomalyFinder(workspace_id, la_data_client)\n", "selected_tables = WidgetViewHelper.select_multiple_tables(anomaly_lookup)\n", "display(selected_tables)" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "gather": { "logged": 1602004939373 }
      }
    },
    {
      "cell_type": "code",
      "source": [ "# Query data: this action may take a few minutes or more, please be patient.\n", "start = timeit.default_timer()\n", "anomalies, queries = anomaly_lookup.run(q_timestamp.value, q_entity.value, list(selected_tables.value))\n", "\n", "print('======= Task completed ===========')\n", "print('Elapsed time: ', timeit.default_timer() - start, ' seconds')\n", "\n", "if anomalies is not None:\n", "    print(str(len(anomalies)) + ' records found.')\n", "else:\n", "    print('0 records found.')" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "gather": { "logged": 1602005204910 }
      }
    },
    {
      "cell_type": "code",
      "source": [ "# Display query result in DataFrame\r\n", "if anomalies is not None and len(anomalies) > 0:\r\n", "    pd.set_option('display.max_rows', None)\r\n", "    pd.set_option('display.max_columns', None)\r\n", "    pd.set_option('display.width', None)\r\n", "    sorted_anomalies = anomalies.sort_values(by=['anomalyScore'], ascending=False)\r\n", "    display(sorted_anomalies)" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": { "transient": { "deleting": false } },
        "trusted": true,
        "gather": { "logged": 1602024174474 }
      }
    },
    {
      "cell_type": "code",
      "source": [ "# Save results to a csv file in the current file system\r\n", "if anomalies is not None and len(anomalies) > 0:    \r\n", "    anomalies.to_csv('anomaly_lookup.csv')" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": { "transient": { "deleting": false } },
        "gather": { "logged": 1602024180389 }
      }
    },
    {
      "cell_type": "code",
      "source": [ "# ML Clustering based on anomalyScore\r\n", "if anomalies is not None and len(anomalies) > 0:\r\n", "    import matplotlib.pyplot as plt\r\n", "    from sklearn.cluster import KMeans\r\n", "    anomaly_score_set = anomalies.iloc[:, [12]].copy()\r\n", "\r\n", "    kmeans = KMeans(n_clusters=3).fit(anomaly_score_set)\r\n", "    centroids = kmeans.cluster_centers_\r\n", "    print(centroids)" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": { "transient": { "deleting": false } },
        "gather": { "logged": 1602024259458 }
      }
    },
    {
      "cell_type": "code",
      "source": [ "# Display Top anomaly scores\r\n", "if anomalies is not None and len(anomalies) > 0 and anomaly_score_set is not None:\r\n", "    top_anomalies = anomaly_score_set.loc[anomaly_score_set['anomalyScore'] > \"5\"]\r\n", "    print(top_anomalies)" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": { "transient": { "deleting": false } },
        "gather": { "logged": 1602025156866 }
      }
    },
    {
      "cell_type": "code",
      "source": [ "# More data columns for top anomalies\r\n", "if anomalies is not None and len(anomalies) > 0:\r\n", "    anomaly_selected = anomalies.iloc[:, [7,8,12,10,11]].copy()\r\n", "    top_anomaly_set = anomaly_selected.loc[anomaly_selected['anomalyScore'] > '4']\r\n", "\r\n", "    # Create a KQL for querying Log analytics for \r\n", "    top_query = selected_tables.value[0] \r\n", "    top_query += ' | where TimeGenerated > datetime(' + q_timestamp.value + 'T23:59:59.000001Z)-14d and TimeGenerated < datetime(' + q_timestamp.value + 'T23:59:59.000001Z)'\r\n", "\r\n", "    count = 0\r\n", "    for index, row in top_anomaly_set.iterrows():\r\n", "        if count == 0:\r\n", "            top_query += ' | where ' + row['colName'] + ' == \\'' + row['colVal'] + '\\' '\r\n", "        else:\r\n", "            top_query += ' or ' + row['colName'] + ' == \\'' + row['colVal'] + '\\' '\r\n", "        \r\n", "        count += 1\r\n", "    \r\n", "    top_query = top_query.replace('\\\\', '\\\\\\\\')\r\n", "else:\r\n", "    top_query = None" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": { "transient": { "deleting": false } },
        "gather": { "logged": 1602025160010 }
      }
    },
    {
      "cell_type": "code",
      "source": [ "# Retrieving top anomaly records from Log Analytics\r\n", "if top_query is not None:\r\n", "    df = anomaly_lookup.query_loganalytics(top_query)\r\n", "    display(df)" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": { "transient": { "deleting": false } },
        "gather": { "logged": 1602025165031 }
      }
    },
    {
      "cell_type": "code",
      "source": [ "# You also can go to Azure Log Analytics for further analysis\r\n", "if queries is not None:\r\n", "    url = WidgetViewHelper.construct_url_for_log_analytics_logs(tenant_id, subscription_id, resource_group, workspace_name)\r\n", "    print('======= Clicking the URL to go to Log Analytics =======')\r\n", "    print(url)\r\n", "\r\n", "    if len(queries) > 2000:\r\n", "        print('======= Copy the queries to go to Log Analytics =======')\r\n", "        print(queries)\r\n", "    else:\r\n", "        WidgetViewHelper.display_html(WidgetViewHelper.copy_to_clipboard(url, queries, 'Add queries to clipboard then paste to Logs'))" ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": { "transient": { "deleting": false } },
        "gather": { "logged": 1602025176670 }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": { "transient": { "deleting": false } }
      }
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": { "name": "python3-azureml" },
    "nteract": { "version": "nteract-front-end@1.0.0" }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}