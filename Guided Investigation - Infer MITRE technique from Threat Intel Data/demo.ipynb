{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Exploration - Infer MITRE technique from Threat Intel Data\n",
    "\n",
    "__Notebook Version:__ 1.0 <br>\n",
    "__Notebook Author:__ Vani Asawa<br>\n",
    "\n",
    "\n",
    "__Python Version:__ >=Python 3.8<br>\n",
    "__Platforms Supported:__  Azure Machine Learning Notebooks<br>\n",
    "\n",
    "__Data Source Required:__ None<br>\n",
    "\n",
    "__GPU Compute Required:__ No<br>\n",
    "__GPU Compute Recommended:__ Yes<br>\n",
    "\n",
    "__Requirements Path:__ ```Guided Exploration - Infer MITRE technique from Threat Intel Data/requirements.txt```<br>\n",
    "__Essential Packages:__ \n",
    "- ipywidgets==7.5.1\n",
    "- transformers==4.5.1\n",
    "- torch==1.10.2\n",
    "- msticpy==2.1.2\n",
    "- nltk==3.6.2\n",
    "- iocextract==1.13.1\n",
    "- shap==0.41.0\n",
    "\n",
    "## Description\n",
    "**Cyber Threat Intelligence** (CTI) provides a framework for threat analysts to document the operations of a threat actor group and record the findings of their investigations of specific cyber attack incidents.\n",
    "\n",
    "With the increasing number and sophistication of attacks occuring across organization's workspace CTI allows organisations to develop a more robust and proactive security posture better detect threat vulnerabilities in their infrastructre and adopt security solutions and policies that allow them to better protect their environment. For example **Indicators of Compromise (IoC)** represent network artifacts of a cyber intrusion and are widely used in intrusion detection systems and antivirus softwares to detect future attacks.\n",
    "\n",
    "**Threat Intel Data** is another form of CTI which comprises of rich unstructured textual data describing the tools techniques and procedures used by threat actor groups in a cyber operation. Historically TI data is made available to the security community in the form of blog posts reports and white papers. With the increasing numebr of cyber attacks it is not scalable to manually process this growing corpus of TI data to understand the motivations capabilities and TTPs associated with an actor group. Additionally TI data does not facilitate easy extraction of IoCs which if documented in the report can result in the loss of known indicators in the threat intelligence corpus. This opens up several avenues for **Machine Learning** more particularly **Natural Language Processing** (NLP) to identify TTPs and IoCs from this data.\n",
    "\n",
    "The **MITRE ATT&CK** framework is an openly-sourced knowledge base of TTPs used by adversaries across enterprise and mobile applications. MITRE TTPs allow people and organizations to proactively identify vulnerabilites in their system based on the behaviors methods and patterns of activity used by an actor group in different stages of a cyber operation.\n",
    "\n",
    "#################################\n",
    "\n",
    "In this notebook we use NLP to\n",
    "1. *Detect MITRE TTPs* &\n",
    "2. *Extract IoCs*\n",
    "\n",
    "from unstructured English text-based Threat Intel data. We also provide some explainability into the TTP predictions made by our NLP model by identifying specific words or phrases in the input TI data that contribute to the prediction.\n",
    "\n",
    "#################################\n",
    "\n",
    "## Prerequisites\n",
    "**Please do not run the notebook cells all at once**. The cells need to be run sequentially and successfully executed before proceeding with the remainder of the notebook.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. Imports\n",
    "2. Configure Input Data and Model Parameters\n",
    "3. Get Model Artifacts\n",
    "4. Process TI Data\n",
    "5. Inference\n",
    "6. Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations\n",
    "\n",
    "Please download the packages in ```Guided Exploration - Infer MITRE technique from Threat Intel Data/requirements.txt``` in your virtual environment before running the rest of the cells in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "############### REQUIREMENTS.TXT NEEDS TO BE UPDATED ################\n",
    "# requirements_path = os.path.join(os.getcwd() 'requirements.txt')\n",
    "# os.system(f'pip install -r {requirements_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports\n",
    "\n",
    "The modules used to run this notebook can be found under ```Guided Exploration - Infer MITRE technique from Threat Intel Data/utils/*```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils\n",
    "from utils import (\n",
    "    configs as config_utils,\n",
    "    storage as storage_utils,\n",
    "    inference as inference_utils,\n",
    "    process as process_utils,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Input Data and Model Parameters,\n",
    "The notebook requires the following parameters from the user:\n",
    "1. ***Threat Intel Data***: Unstructured, English text data that the user would like to process through the NLP model. If you are inputting multiple text reports in the widget, please input the reports separated by an empty line. Do not include any commas, punctuations, or brackets before and after the reports. <br>\n",
    "- For example: Here, we are processing three different threat reports, which are separated by an empty line. The length of each report can be more than one sentence. In this example, for the purposes of succinct documentation, the length of each report is 1 sentence.\n",
    "\n",
    "    ```\n",
    "    Like many threat groups, TG-3390 conducts strategic web compromises (SWCs), also known as watering hole attacks, on websites associated with the target organization's vertical or demographic to increase the likelihood of finding victims with relevant information.\n",
    "\n",
    "    Threat groups use strategic web compromises (SWCs), also known as watering hole attacks, to target a wide array of potential victims.\n",
    "\n",
    "    A build tool is likely being used by these attackers that allows the operator to configure details such as C2 addresses, C2 encryption keys, and a campaign code.\n",
    "    ```\n",
    "       \n",
    "2. ***Select NLP Model***: We have trained four variations of GPT-2 transformer models using publicly-available threat intel datasets that map TI data to MITRE TTPs. \n",
    "- *distilgpt2* models are 40% lower in storage size than the *gpt2* models <br>\n",
    "\n",
    "- *distilgpt2-1024* and *gpt2-1024* models process more word tokens in a single threat input statement than the *distilgpt2-512* and *distilgpt2-1024* models, which can be particularly useful if your threat intel data is long. <br>\n",
    "\n",
    "- Default model: **distilgpt2_512** <br><br>\n",
    "\n",
    "3. ***Minimum Score Threshold***: The TTP predictions for a sample TI input data have an associated confidence score from the NLP model, ranging from 0 (less confident) to 1 (most confident). Filter the results to predictions with confidence >= threshold configured by the user. <br>\n",
    "\n",
    "- Default threshold: **0.7** <br> <br>\n",
    "       \n",
    "4. ***Chunk Threat Intel Data?***: \n",
    "- One of the limitations of the transformer models is that they can only process inputs upto a certain length, after which the rest of the report is discarded. \n",
    "- As a result, the model will lose out on potentially important information about the actor's TTPs, described in the latter parts of the report. \n",
    "- If a single threat report in your input is longer than 3 sentences, we recommend **chunking** - The model will process the sentences in your input data in batches of 3 sentences, hence assigning a TTP prediction for each chunk of data, and processing the entire report. <br>\n",
    "\n",
    "- Default value: **Yes** <br><br>\n",
    "\n",
    "5. ***Extract Indicators of Compromise (IoCs)***: Extract IoCs from the input TI data. <br>\n",
    "\n",
    "- Default value: **Yes** <br><br>\n",
    "\n",
    "6. ***Get NLP Model Explainability***: Obtain further insights into which words and phrases in your input data contributed to the TTP prediction. <br>\n",
    "\n",
    "- Default value: **Yes** <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_config_widgets = config_utils.configure_model_parameters()\n",
    "for k in all_config_widgets.keys():\n",
    "       display(all_config_widgets[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_configs = {\n",
    "    k: v.value for k, v in all_config_widgets.items()\n",
    "}\n",
    "\n",
    "configs = config_utils.format_user_configuration(set_configs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash ./models.sh {configs['model']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = storage_utils.AssetStorage(\n",
    "    configs['model']\n",
    ")\n",
    "\n",
    "model, tokenizer, labels = assets.model, assets.tokenizer, assets.labels\n",
    "device = assets.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = inference_utils.InferenceClassificationPipeline(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    device = device.type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process TI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_object = process_utils.ProcessData(\n",
    "    configs = configs\n",
    ")\n",
    "\n",
    "processed_data_object.go()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = inference_model.go(processed_data_object.processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = inference_utils.format_predictions(\n",
    "    configs = configs,\n",
    "    processed_data_object = processed_data_object,\n",
    "    labels = labels,\n",
    "    outputs = outputs,\n",
    "    classifier = inference_model.classifier_max_scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of DF: {inference_df.shape}')\n",
    "       \n",
    "print('Sample Result: ')\n",
    "if inference_df.empty:\n",
    "    print('Empty Dataframe')\n",
    "else:\n",
    "    display(inference_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability - Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_index = 2\n",
    "       \n",
    "inference_utils = inference_utils.process_shap_explainability_for_row(\n",
    "    inference_df, row_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9379f31aa79e9f3733e42c9f886d154b4224f9219b4198d46949455f975e1f6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
