{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Office 365 Explorer\n",
    "&lt;details&gt;\n",
    "    <summary> <u>Details...</u></summary>\n",
    "**Notebook Version:** 1.0<br>\n",
    "**Python Version:** Python 3.6 (including Python 3.6 - AzureML)<br>\n",
    "**Required Packages**: kqlmagic, msticpy, pandas, numpy, matplotlib, seaborn, ipywidgets, ipython, scikit_learn, folium, maxminddb_geolite2<br>\n",
    "**Platforms Supported**:\n",
    "- Azure Notebooks Free Compute\n",
    "- Azure Notebooks DSVM\n",
    "- OS Independent\n",
    "\n",
    "**Data Sources Required**:\n",
    "- Log Analytics - OfficeActivity, IPLocation, Azure Network Analytics\n",
    "\n",
    "&lt;/details&gt;\n",
    "\n",
    "Brings together a series of queries and visualizations to help you investigate the security status of Office 365 subscription and individual user activities.\n",
    "- The first section focuses on Tenant-Wide data queries and analysis\n",
    "- The second section allows you to focus on individial accounts and examine them for any suspicious activity.\n",
    "\n",
    "This notebook is intended to be illustrative of the types of data available in Office 365 Activity data and how to query and use them. It is not meant to be used as a prescriptive guide to how to navigate through the data. \n",
    "<br> Feel free to experiment and submit anything interesting you find to the community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>\n",
    "# Table of Contents\n",
    "- [Setup and Authenticate](#setup)\n",
    "- [Office 365 Activity](#o365)\n",
    "  - [Tenant-wide Information](#tenant_info)\n",
    "    - [AAD Operations - Account Modifications](#aad_ops)\n",
    "    - [Logon Anomalies](#logon_anomalies)\n",
    "    - [Activity Summary](#activity_summary)\n",
    "    - [Variability of IP Address for users](#ip_variability)\n",
    "    - [Accounts with multiple IPs and Geolocations](#acct_multi_geo)\n",
    "    - [User Logons with &gt; N IP Address](#acct_multi_ips)\n",
    "    - [Operation Types by Location and IP](#ip_op_matrix)\n",
    "    - [Geolocation Map of Client IPs](#geo_map_tenant)\n",
    "    - [Distinct User Agent Strings in Use](#distinct_uas)\n",
    "    - [Graphical Activity Timeline](#op_timeline)\n",
    "    - [Users With largest Activity Type Count](#user_activity_counts)\n",
    "  - [Office User Investigation](#o365_user_inv)\n",
    "    - [Activity Summary](#user_act_summary)\n",
    "    - [Operation Breakdown for User](#user_op_count)\n",
    "    - [IP Count for Different User Operations](#user_ip_counts)\n",
    "    - [Activity Timeline](#user_act_timeline)\n",
    "    - [User IP GeoMap](#user_geomap)\n",
    "    - [Check for User IPs in Azure Network Flow Data](#ips_in_azure)\n",
    "  - [Rare Combinations of Country/UserAgent/Operation Type](#o365_cluster)\n",
    "- [Appendices](#appendices)\n",
    "  - [Saving data to Excel](#appendices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Initialization\n",
    "This cell:\n",
    "\n",
    "- Checks for the correct Python version\n",
    "- Checks versions and optionally installs required packages\n",
    "- Imports the required packages into the notebook\n",
    "- Sets a number of configuration options.\n",
    "\n",
    "This should complete without errors. If you encounter errors or warnings look at the following two notebooks:\n",
    "- [TroubleShootingNotebooks](https://github.com/Azure/Azure-Sentinel-Notebooks/blob/master/TroubleShootingNotebooks.ipynb)\n",
    "- [ConfiguringNotebookEnvironment](https://github.com/Azure/Azure-Sentinel-Notebooks/blob/master/ConfiguringNotebookEnvironment.ipynb)\n",
    "\n",
    "You may also need to do some additional configuration to successfully use functions such as Threat Intelligence service lookup and Geo IP lookup. See the <a href=\"#Configuration\">Configuration</a> section at the end of the notebook and the [ConfiguringNotebookEnvironment](https://github.com/Azure/Azure-Sentinel-Notebooks/blob/master/ConfiguringNotebookEnvironment.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T21:13:24.369073Z",
     "start_time": "2020-02-28T21:13:24.260137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "display(HTML(\"<h3>Starting Notebook setup...</h3>\"))\n",
    "warn_mssg = []\n",
    "err_mssg = []\n",
    "MISSING_PKG_ERR = \"\"\"\n",
    "    <h3><font color='red'>Warning {package} is not installed or has an incorrect version</h3></font>\n",
    "    For more details, please go to the <a href=\"#Setup\">Setup section</a> at the end of the notebook.\n",
    "    \"\"\"\n",
    "MIN_REQ_PYTHON = (3, 6)\n",
    "PANDAS_REQ_VERSION = (0, 25, 0)\n",
    "MSTICPY_REQ_VERSION = (0, 2, 7)\n",
    "if sys.version_info < MIN_REQ_PYTHON:\n",
    "    display(HTML(\"\"\"\n",
    "    <h2><font color='red'>Incorrect notebook kernel version detected</h2></font>\n",
    "    Please check the <b>Kernel->Change Kernel</b> menu and ensure that <b>Python 3.6</b><br>\n",
    "    or later is selected as the active kernel.\"\"\"))\n",
    "    raise RuntimeError(\"Python %s.%s or later kernel is required.\" % MIN_REQ_PYTHON)\n",
    "\n",
    "print(\n",
    "    \"Python kernel version %s.%s.%s\" % (\n",
    "        sys.version_info[0], sys.version_info[1], sys.version_info[2]\n",
    "    )\n",
    ")\n",
    "try:\n",
    "    import msticpy\n",
    "    mp_version = tuple([int(v) for v in msticpy.__version__.split(\".\")])\n",
    "    if mp_version < MSTICPY_REQ_VERSION:\n",
    "        raise ImportError(\"msticpy %s.%s.%s or later is required.\" % MSTICPY_REQ_VERSION)\n",
    "    print(\"msticpy imported version %s\" % msticpy.__version__)\n",
    "except ImportError:\n",
    "    display(HTML(MISSING_PKG_ERR.format(package=\"msticpy\")))\n",
    "    resp = input(\"Install the package now? (y/n)\")\n",
    "    if resp.casefold().startswith(\"y\"):\n",
    "        !pip install --user --upgrade msticpy\n",
    "        warn_mssg.append(\"msticpy was installed or upgraded.\")\n",
    "        if \"msticpy\" in sys.modules:\n",
    "            importlib.reload(msticpy)\n",
    "        else:\n",
    "            import msticpy\n",
    "\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    import ipywidgets as widgets\n",
    "    from pathlib import Path\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import MatplotlibDeprecationWarning\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    pd_version = tuple([int(v) for v in pd.__version__.split(\".\")])\n",
    "    if pd_version < PANDAS_REQ_VERSION:\n",
    "        display(HTML(MISSING_PKG_ERR.format(package=\"pandas\")))\n",
    "        resp = input(\"Install the package now? (y/n)\")\n",
    "        if resp.casefold().startswith(\"y\"):\n",
    "            warn_mssg.append(\"pandas was installed or upgraded.\")\n",
    "            !pip install --user --upgrade pandas\n",
    "            if \"pandas\" in sys.modules:\n",
    "                importlib.reload(pd)\n",
    "            else:\n",
    "                import pandas as pd\n",
    "    print(\"pandas imported version %s\" % pd.__version__)\n",
    "    from msticpy.data import QueryProvider\n",
    "    from msticpy.nbtools import *\n",
    "    from msticpy.sectools import *\n",
    "    from msticpy.nbtools.foliummap import FoliumMap\n",
    "    from msticpy.nbtools.utility import md, md_warn\n",
    "    from msticpy.nbtools.wsconfig import WorkspaceConfig\n",
    "    \n",
    "    additional_packages = []\n",
    "    if additional_packages:\n",
    "        utils.check_and_install_missing_packages(additional_packages)\n",
    "        \n",
    "    from dns import reversename, resolver\n",
    "    from ipwhois import IPWhois\n",
    "\n",
    "except ImportError as imp_err:\n",
    "    display(HTML(\"\"\"\n",
    "    <h2><font color='red'>One or more missing packages detected</h2>\n",
    "    Please correct these by installing the required packages, restart\n",
    "    the kernel and re-run the notebook.</font>\n",
    "    <i>Package error: %s</i><br>\n",
    "    \"\"\" % imp_err))\n",
    "    err_mssg.append(\"One or more missing packages found.\")\n",
    "\n",
    "else:\n",
    "    mp_path = os.environ.get(\"MSTICPYCONFIG\", \"./msticpyconfig.yaml\")\n",
    "    if not Path(mp_path).exists():\n",
    "        display(HTML(\"\"\"\n",
    "        <h3><font color='orange'>Warning: no <i>msticpyconfig.yaml</i> found</h3></font>\n",
    "        Some functionality (such as Threat Intel lookups) will not function without valid configuration\n",
    "        settings. \n",
    "        Please go to the <a href=\"#Setup\">Setup section</a> follow the instructions there.\n",
    "        \"\"\"))\n",
    "        warn_mssg.append(\"msticpyconfig.yaml not found.\")\n",
    "\n",
    "    WIDGET_DEFAULTS = {\n",
    "        \"layout\": widgets.Layout(width=\"95%\"),\n",
    "        \"style\": {\"description_width\": \"initial\"},\n",
    "    }\n",
    "\n",
    "    # Some of our dependencies still use deprecated Matplotlib\n",
    "    # APIs - we can't do anything about it, so suppress them from view\n",
    "    warnings.simplefilter(\"ignore\", category=MatplotlibDeprecationWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    sns.set()\n",
    "    pd.set_option(\"display.max_rows\", 100)\n",
    "    pd.set_option(\"display.max_columns\", 50)\n",
    "    pd.set_option(\"display.max_colwidth\", 100)\n",
    "    os.environ[\"KQLMAGIC_LOAD_MODE\"]=\"silent\"\n",
    "\n",
    "with_errs = \"<br>with %s errors\" % len(err_mssg) if err_mssg else \"\"\n",
    "with_warns = \"<br>with %s warnings\" % len(warn_mssg) if warn_mssg else \"\"\n",
    "\n",
    "if err_mssg:\n",
    "    display(HTML(\"<font color='red'><h3>Errors:</h3>\" + '<br>'.join(err_mssg)))\n",
    "if warn_mssg:\n",
    "    display(HTML(\"<font color='red'><h3>Warnings:</h3>\" + '<br>'.join(warn_mssg)))\n",
    "\n",
    "display(HTML(\"<h3>Notebook setup complete</h3>\" + with_errs + with_warns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "source": [
    "### Get WorkspaceId and Authenticate to Log Analytics \n",
    "&lt;details&gt;\n",
    "    <summary> <u>Details...</u></summary>\n",
    "If you are using user/device authentication, run the following cell. \n",
    "- Click the 'Copy code to clipboard and authenticate' button.\n",
    "- This will pop up an Azure Active Directory authentication dialog (in a new tab or browser window). The device code will have been copied to the clipboard. \n",
    "- Select the text box and paste (Ctrl-V/Cmd-V) the copied value. \n",
    "- You should then be redirected to a user authentication page where you should authenticate with a user account that has permission to query your Log Analytics workspace.\n",
    "\n",
    "Use the following syntax if you are authenticating using an Azure Active Directory AppId and Secret:\n",
    "```\n",
    "%kql loganalytics://tenant(aad_tenant).workspace(WORKSPACE_ID).clientid(client_id).clientsecret(client_secret)\n",
    "```\n",
    "instead of\n",
    "```\n",
    "%kql loganalytics://code().workspace(WORKSPACE_ID)\n",
    "```\n",
    "\n",
    "Note: you may occasionally see a JavaScript error displayed at the end of the authentication - you can safely ignore this.<br>\n",
    "On successful authentication you should see a ```popup schema``` button.\n",
    "To find your Workspace Id go to [Log Analytics](https://ms.portal.azure.com/#blade/HubsExtension/Resources/resourceType/Microsoft.OperationalInsights%2Fworkspaces). Look at the workspace properties to find the ID.\n",
    "&lt;/details&gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To list configured workspaces run WorkspaceConfig.list_workspaces()\n",
    "# WorkspaceConfig.list_workspaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:45:14.575554Z",
     "start_time": "2019-10-31T23:44:52.55913Z"
    },
    "tags": [
     "todo"
    ]
   },
   "outputs": [],
   "source": [
    "# Authentication\n",
    "ws_config = WorkspaceConfig()\n",
    "qry_prov = QueryProvider(data_environment=\"LogAnalytics\")\n",
    "qry_prov.connect(connection_str=ws_config.code_connect_str)\n",
    "table_index = qry_prov.schema_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "# Office 365 Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Analytics Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:45:48.722304Z",
     "start_time": "2019-10-31T23:45:48.71349Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'OfficeActivity' not in table_index:\n",
    "    display(Markdown('<font color=\"red\"><h2>Warning. Office Data not available.</h2></font><br>'\n",
    "                     'Either Office 365 data has not been imported into the workspace or'\n",
    "                     ' the OfficeActivity table is empty.<br>'\n",
    "                     'This workbook is not useable with the current workspace.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:54:12.67834Z",
     "start_time": "2019-10-31T23:54:12.500495Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the origin time to the time of our alert\n",
    "o365_query_times = nbwidgets.QueryTime(units='hours',\n",
    "                           before=24, after=1, max_before=120, max_after=20)\n",
    "o365_query_times.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:54:13.328357Z",
     "start_time": "2019-10-31T23:54:13.312114Z"
    }
   },
   "outputs": [],
   "source": [
    "iplocation = GeoLiteLookup()\n",
    "\n",
    "# Queries\n",
    "office_ops_query = '''\n",
    "OfficeActivity\n",
    "| where TimeGenerated >= datetime({start})\n",
    "| where TimeGenerated <= datetime({end})\n",
    "| where RecordType in (\"AzureActiveDirectoryAccountLogon\", \"AzureActiveDirectoryStsLogon\")\n",
    "| extend UserAgent = extractjson(\"$[0].Value\", ExtendedProperties, typeof(string))\n",
    "| union (\n",
    "    OfficeActivity \n",
    "    | where TimeGenerated >= datetime({start})\n",
    "    | where TimeGenerated <= datetime({end})\n",
    "    | where RecordType !in (\"AzureActiveDirectoryAccountLogon\", \"AzureActiveDirectoryStsLogon\")\n",
    ")\n",
    "| where UserType == 'Regular'\n",
    "'''\n",
    "\n",
    "\n",
    "office_ops_summary_query = '''\n",
    "OfficeActivity \n",
    "| where TimeGenerated >= datetime({start})\n",
    "| where TimeGenerated <= datetime({end})\n",
    "| where RecordType !in (\"AzureActiveDirectoryAccountLogon\", \"AzureActiveDirectoryStsLogon\")\n",
    "| where UserType == 'Regular'\n",
    "| extend RecordOp = strcat(RecordType, '-', Operation)\n",
    "| summarize OperationCount=count() by RecordType, Operation, UserId, UserAgent, ClientIP, bin(TimeGenerated, 1h)\n",
    "// render timeline\n",
    "'''\n",
    "\n",
    "\n",
    "office_logons_byua_query = '''\n",
    "let end = datetime({end});\n",
    "let threshold={threshold};\n",
    "let start = end - 1d;\n",
    "let hist_start = start - 30d;\n",
    "let hist_end = end;\n",
    "let officeAuthentications = OfficeActivity\n",
    "| where TimeGenerated >= hist_start\n",
    "| where TimeGenerated <= hist_end\n",
    "| where RecordType in (\"AzureActiveDirectoryAccountLogon\", \"AzureActiveDirectoryStsLogon\")\n",
    "| extend UserAgent = extractjson(\"$[0].Value\", ExtendedProperties, typeof(string))\n",
    "| where Operation == \"UserLoggedIn\";\n",
    "let lookupWindow = end - start;\n",
    "let lookupBin = lookupWindow / 2.0; \n",
    "officeAuthentications \n",
    "| project-rename Start = TimeGenerated\n",
    "| extend TimeKey = bin(Start, lookupBin)\n",
    "| join kind = inner (\n",
    "    officeAuthentications\n",
    "    | project-rename End = TimeGenerated\n",
    "    | extend TimeKey = range(bin(End - lookupWindow, lookupBin), bin(End, lookupBin), lookupBin)\n",
    "    | mvexpand TimeKey to typeof(datetime)\n",
    ") on UserAgent, TimeKey\n",
    "| project timeSpan = End - Start, UserId, ClientIP , UserAgent , Start, End\n",
    "| summarize Count_ClientIP = dcount(ClientIP) by UserId\n",
    "| where Count_ClientIP > threshold\n",
    "| join kind=inner (  \n",
    "    officeAuthentications\n",
    "    | summarize minTime=min(TimeGenerated), maxTime=max(TimeGenerated) by UserId, UserAgent, ClientIP\n",
    ") on UserAgent\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "## Tenant-wide Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Summary of O365 Activity Types\n",
    "#### <font>Warning this query can be time consuming for large O365 subscriptions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:54:57.676564Z",
     "start_time": "2019-10-31T23:54:57.061956Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Getting data...', end=' ')\n",
    "o365_query = office_ops_summary_query.format(start = o365_query_times.start, \n",
    "                                             end=o365_query_times.end)\n",
    "%kql -query o365_query\n",
    "office_ops_summary_df = _kql_raw_result_.to_dataframe()\n",
    "print('done.')\n",
    "(office_ops_summary_df\n",
    " .assign(UserId = lambda x: x.UserId.str.lower())\n",
    " .groupby(['RecordType', 'Operation'])\n",
    " .aggregate({'ClientIP': 'nunique',\n",
    "             'UserId': 'nunique',\n",
    "             'OperationCount': 'sum'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Variability of IP Address for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "height = math.log10(4) * 2\n",
    "aspect = 10 / height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:55:06.51199Z",
     "start_time": "2019-10-31T23:55:03.446846Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_ip_op_ua = (office_ops_summary_df.assign(UserId = lambda x: x.UserId.str.lower())\n",
    "                   .groupby(['UserId', 'Operation'])\n",
    "                   .aggregate({'ClientIP': 'nunique', 'OperationCount': 'sum'})\n",
    "                   .reset_index()\n",
    "                   .rename(columns={\"ClientIP\": \"ClientIPCount\"})\n",
    "                  )\n",
    "\n",
    "import math\n",
    "height = max(math.log10(len(unique_ip_op_ua.UserId.unique())) * 2, 4)\n",
    "aspect = 10 / height\n",
    "user_ip_op = sns.catplot(x=\"ClientIPCount\", y=\"UserId\", hue='Operation', data=unique_ip_op_ua, height=height, aspect=aspect)\n",
    "display(Markdown('Variability of IP Address Usage by user'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Accounts with multiple IPs and Geolocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:55:15.689167Z",
     "start_time": "2019-10-31T23:55:15.407802Z"
    }
   },
   "outputs": [],
   "source": [
    "restrict_cols = ['RecordType', 'TimeGenerated', 'Operation',\n",
    "                 'UserId', 'ClientIP', 'UserAgent']\n",
    "office_ops_summary = office_ops_summary_df[restrict_cols].assign(UserId = lambda x: x.UserId.str.lower())\n",
    "unique_ip_op_ua['ClientIPCount'] = unique_ip_op_ua['ClientIPCount']\n",
    "office_ops_merged = pd.merge(unique_ip_op_ua.query('ClientIPCount > 1').drop(columns='ClientIPCount'), \n",
    "                             office_ops_summary,\n",
    "                             on=['UserId', 'Operation'])\n",
    "\n",
    "\n",
    "client_ips = office_ops_merged.query('ClientIP != \"<null>\" & ClientIP != \"\"')['ClientIP'].drop_duplicates().tolist()\n",
    "ip_entities = []\n",
    "for ip in client_ips:\n",
    "    ip_entity = entities.IpAddress(Address=ip)\n",
    "    iplocation.lookup_ip(ip_entity=ip_entity)\n",
    "    if ip_entity.Location:\n",
    "        ip_dict = {'Address': ip_entity.Address}\n",
    "        ip_dict.update(ip_entity.Location.properties)\n",
    "        ip_entities.append(pd.Series(ip_dict))\n",
    "\n",
    "ip_locs_df = pd.DataFrame(data=ip_entities)\n",
    "ip_locs_df\n",
    "\n",
    "office_ops_summary_ip_loc = pd.merge(office_ops_merged, \n",
    "                                     ip_locs_df, left_on='ClientIP', \n",
    "                                     right_on='Address', how='left')\n",
    "\n",
    "(office_ops_summary_ip_loc.groupby(['UserId', 'CountryCode', 'City'])\n",
    "                   .aggregate({'ClientIP': 'nunique', 'OperationCount': 'sum'})).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Choose threshold to show User Logons where User has logged on from &gt; N IP Address in period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:55:31.462114Z",
     "start_time": "2019-10-31T23:55:31.392922Z"
    }
   },
   "outputs": [],
   "source": [
    "th_wgt = widgets.IntSlider(value=1, min=1, max=50, step=1, description='Set IP Count Threshold', **WIDGET_DEFAULTS)\n",
    "th_wgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Matrix of Selected Operation Types by Location and IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:55:43.092247Z",
     "start_time": "2019-10-31T23:55:41.363322Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Getting data...', end=' ')\n",
    "o365_query = office_ops_query.format(start=o365_query_times.start, \n",
    "                                     end=o365_query_times.end)\n",
    "# %kql -query o365_query\n",
    "# office_ops_df = _kql_raw_result_.to_dataframe()\n",
    "office_ops_df = qry_prov.exec_query(o365_query)\n",
    "print('done.') \n",
    "\n",
    "# Get Locations for distinct IPs\n",
    "client_ips = office_ops_df.query('ClientIP != \"<null>\" & ClientIP != \"\"')['ClientIP'].drop_duplicates().tolist()\n",
    "ip_entities = []\n",
    "for ip in client_ips:\n",
    "    ip_entity = entities.IpAddress(Address=ip)\n",
    "    iplocation.lookup_ip(ip_entity=ip_entity)\n",
    "    if ip_entity.Location:\n",
    "        ip_dict = {'Address': ip_entity.Address}\n",
    "        ip_dict.update(ip_entity.Location.properties)\n",
    "        ip_entities.append(pd.Series(ip_dict))\n",
    "\n",
    "ip_locs_df = pd.DataFrame(data=ip_entities)\n",
    "\n",
    "# Get rid of unneeded columns\n",
    "restrict_cols = ['OfficeId', 'RecordType', 'TimeGenerated', 'Operation',\n",
    "                 'OrganizationId', 'UserType', 'UserKey', 'OfficeWorkload',\n",
    "                 'ResultStatus', 'OfficeObjectId', 'UserId', 'ClientIP','UserAgent']\n",
    "office_ops_restr = office_ops_df[restrict_cols]\n",
    "\n",
    "# Merge main DF with IP location data\n",
    "office_ops_locs = pd.merge(office_ops_restr, ip_locs_df, how='right', left_on='ClientIP', right_on='Address',\n",
    "         indicator=True)\n",
    "\n",
    "limit_op_types = ['FileDownloaded', 'FileModified','FileUploaded',\n",
    "                  'MailboxLogin']\n",
    "\n",
    "office_ops_locs = office_ops_locs[office_ops_locs.Operation.isin(limit_op_types)]\n",
    "\n",
    "# Calculate operations grouped by location and operation type\n",
    "cm = sns.light_palette(\"yellow\", as_cmap=True)\n",
    "country_by_op_count = (office_ops_locs[['Operation', 'RecordType', 'CountryCode', 'City']]\n",
    "                        .groupby(['CountryCode', 'City', 'Operation'])\n",
    "                        .count())\n",
    "display(country_by_op_count.unstack().fillna(0).rename(columns={'RecordType':'OperationCount'}))\n",
    "#         .style.background_gradient(cmap=cm))\n",
    "\n",
    "# Group by Client IP, Country, Operation\n",
    "clientip_by_op_count = (office_ops_locs[['ClientIP', 'Operation', 'RecordType', 'CountryCode']]\n",
    "                        .groupby(['ClientIP', 'CountryCode', 'Operation'])\n",
    "                        .count())\n",
    "\n",
    "(clientip_by_op_count.unstack().fillna(0).rename(columns={'RecordType':'OperationCount'}))\n",
    "#  .style.background_gradient(cmap=cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Geolocation Map of Client IPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:55:48.110586Z",
     "start_time": "2019-10-31T23:55:47.928169Z"
    }
   },
   "outputs": [],
   "source": [
    "from msticpy.nbtools.foliummap import FoliumMap\n",
    "folium_map = FoliumMap(zoom_start=3)\n",
    "\n",
    "def get_row_ip_loc(row):\n",
    "    try:\n",
    "        _, ip_entity = iplocation.lookup_ip(ip_address=row.ClientIP)\n",
    "        return ip_entity\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "off_ip_locs = (office_ops_df[['ClientIP']]\n",
    "                   .drop_duplicates()\n",
    "                   .apply(get_row_ip_loc, axis=1)\n",
    "                   .tolist())\n",
    "ip_locs = [ip_list[0] for ip_list in off_ip_locs if ip_list]\n",
    "    \n",
    "display(HTML('<h3>External IP Addresses seen in Office Activity</h3>'))\n",
    "display(HTML('Numbered circles indicate multiple items - click to expand.'))\n",
    "\n",
    "\n",
    "icon_props = {'color': 'purple'}\n",
    "folium_map.add_ip_cluster(ip_entities=ip_locs,\n",
    "                          **icon_props)\n",
    "folium_map.center_map()\n",
    "display(folium_map.folium_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Graphical Activity Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:56:06.917689Z",
     "start_time": "2019-10-31T23:56:04.088006Z"
    }
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    display(Markdown('### Change in rate of Activity Class (RecordType) and Operation'))\n",
    "    sns.relplot(data=office_ops_summary_df, x='TimeGenerated', y='OperationCount', kind='line', aspect=2, \n",
    "                hue='RecordType')\n",
    "    sns.relplot(data=office_ops_summary_df.query('RecordType == \"SharePointFileOperation\"'), \n",
    "                x='TimeGenerated', y='OperationCount', hue='Operation', kind='line', aspect=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Users With largest Activity Type Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:56:29.31557Z",
     "start_time": "2019-10-31T23:56:27.559526Z"
    }
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    display(Markdown('### Identify Users/IPs with largest operation count'))\n",
    "    office_ops = office_ops_summary_df.assign(Account=lambda x: \n",
    "                                              (x.UserId.str.extract('([^@]+)@.*', expand=False)).str.lower())\n",
    "\n",
    "    limit_op_types = ['FileDownloaded', 'FileModified','FileUploaded',\n",
    "                      'MailboxLogin']\n",
    "    office_ops = office_ops[office_ops.Operation.isin(limit_op_types)]\n",
    "    \n",
    "    sns.catplot(data=office_ops, y='Account', x='OperationCount', \n",
    "                hue='Operation', aspect=2)\n",
    "    display(office_ops.pivot_table('OperationCount', index=['Account'], \n",
    "                                   columns='Operation').style.bar(color='orange', align='mid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:56:34.872881Z",
     "start_time": "2019-10-31T23:56:34.671452Z"
    }
   },
   "outputs": [],
   "source": [
    "off_ops_df = office_ops_df[['OfficeId', 'RecordType', 'TimeGenerated', 'Operation',\n",
    "       'OrganizationId', 'UserType', 'UserKey', 'OfficeWorkload',\n",
    "       'ResultStatus', 'OfficeObjectId', 'UserId', 'ClientIP','UserAgent']]\n",
    "(pd.merge(off_ops_df, ip_locs_df, how='left', left_on='ClientIP', right_on='Address')\n",
    " [['TimeGenerated', 'Operation', 'RecordType', 'OfficeWorkload',\n",
    "   'ResultStatus', 'UserId', 'ClientIP', 'UserAgent', 'CountryCode',\n",
    "   'CountryName', 'State', 'City', 'Longitude', 'Latitude'\n",
    "  ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "## Office User Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:58:20.694357Z",
     "start_time": "2019-10-31T23:58:20.462823Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the origin time to the time of our alert\n",
    "o365_query_times_user = nbwidgets.QueryTime(units='days',\n",
    "                           before=10, after=1, max_before=60, max_after=20, auto_display=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:58:23.81571Z",
     "start_time": "2019-10-31T23:58:23.679707Z"
    }
   },
   "outputs": [],
   "source": [
    "distinct_users = office_ops_df[['UserId']].sort_values('UserId')['UserId'].str.lower().drop_duplicates().tolist()\n",
    "distinct_users\n",
    "user_select = nbwidgets.SelectString(description='Select User Id', item_list=distinct_users, auto_display=True)\n",
    "                               # (items=distinct_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Activity Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:58:27.844773Z",
     "start_time": "2019-10-31T23:58:26.75675Z"
    }
   },
   "outputs": [],
   "source": [
    "# Provides a summary view of a given account's activity\n",
    "# For use when investigating an account that has been identified as having associated suspect activity or been otherwise compromised. \n",
    "# All office activity by UserName using UI to set Time range\n",
    "# Tags: #Persistence, #Discovery, #Lateral Movement, #Collection\n",
    "\n",
    "user_activity_query = '''\n",
    "OfficeActivity\n",
    "| where TimeGenerated >= datetime({start})\n",
    "| where TimeGenerated <= datetime({end})\n",
    "| where UserKey has \"{user}\" or UserId has \"{user}\"\n",
    "'''\n",
    "print('Getting data...', end=' ')\n",
    "o365_query = user_activity_query.format(start=o365_query_times_user.start, \n",
    "                                        end=o365_query_times_user.end,\n",
    "                                        user=user_select.value)\n",
    "%kql -query o365_query\n",
    "user_activity_df = _kql_raw_result_.to_dataframe()\n",
    "print('done.')\n",
    "user_activity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Operation Breakdown for User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:58:31.861898Z",
     "start_time": "2019-10-31T23:58:30.61838Z"
    }
   },
   "outputs": [],
   "source": [
    "my_df = (user_activity_df[['OfficeId', 'RecordType', 'TimeGenerated', 'Operation',\n",
    "                           'ResultStatus', 'UserId', 'ClientIP','UserAgent']]\n",
    "         .groupby(['Operation', 'ResultStatus', 'ClientIP'])\n",
    "         .aggregate({'OfficeId': 'count'})\n",
    "         .rename(columns={'OfficeId': 'OperationCount', 'ClientIP': 'IPCount'})\n",
    "         .reset_index())\n",
    "sns.catplot(x='OperationCount', y=\"Operation\", hue=\"ClientIP\", jitter=False, data=my_df, aspect=2.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### IP Count for Different User Operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:58:35.643369Z",
     "start_time": "2019-10-31T23:58:35.048874Z"
    }
   },
   "outputs": [],
   "source": [
    "my_df2 = (user_activity_df[['OfficeId', 'RecordType', 'TimeGenerated', 'Operation',\n",
    "                           'ResultStatus', 'UserId', 'ClientIP','UserAgent']]\n",
    "         .groupby(['Operation'])\n",
    "         .aggregate({'OfficeId': 'count', 'ClientIP': 'nunique'})\n",
    "         .rename(columns={'OfficeId': 'OperationCount', 'ClientIP': 'IPCount'})\n",
    "         .reset_index())\n",
    "sns.barplot(x='IPCount', y=\"Operation\", data=my_df2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Activity Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:58:38.912584Z",
     "start_time": "2019-10-31T23:58:38.510034Z"
    }
   },
   "outputs": [],
   "source": [
    "nbdisplay.display_timeline(data=user_activity_df,\n",
    "                           title='Office Operations',\n",
    "                           source_columns=['OfficeWorkload', 'Operation', 'ClientIP', 'ResultStatus'],\n",
    "                           group_by=\"Operation\",\n",
    "                           height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### User IP GeoMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:58:42.359786Z",
     "start_time": "2019-10-31T23:58:42.24363Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_row_ip_loc(row):\n",
    "    try:\n",
    "        _, ip_entity = iplocation.lookup_ip(ip_address=row.ClientIP)\n",
    "        return ip_entity\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "from msticpy.nbtools.foliummap import FoliumMap\n",
    "folium_map = FoliumMap(zoom_start=3)\n",
    "off_ip_locs = (user_activity_df[['ClientIP']]\n",
    "                   .drop_duplicates()\n",
    "                   .apply(get_row_ip_loc, axis=1)\n",
    "                   .tolist())\n",
    "ip_locs = [ip_list[0] for ip_list in off_ip_locs if ip_list]\n",
    "    \n",
    "display(HTML('<h3>External IP Addresses seen in Office Activity</h3>'))\n",
    "display(HTML('Numbered circles indicate multiple items - click to expand.'))\n",
    "\n",
    "\n",
    "icon_props = {'color': 'purple'}\n",
    "folium_map.add_ip_cluster(ip_entities=ip_locs,\n",
    "                          **icon_props)\n",
    "folium_map.center_map()\n",
    "display(folium_map.folium_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "### Check for User IPs in Azure Network Flow Data\n",
    "The full data is available in the Dataframe ```az_net_query_byip```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    qry_prov\n",
    "    .Network\n",
    "    .list_azure_network_flows_by_ip(\"print\", start=o365_query_times_user.start,\n",
    "                                    end=o365_query_times_user.end,\n",
    "                                    ip_address_list=all_user_ips)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:58:53.22893Z",
     "start_time": "2019-10-31T23:58:49.47013Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'AzureNetworkAnalytics_CL' not in table_index:\n",
    "    display(Markdown('<font color=\"red\"><h2>Warning. Azure network flow data not available.</h2></font><br>'\n",
    "                     'This section of the notebook is not useable with the current workspace.'))\n",
    "    \n",
    "# Build the query parameters\n",
    "all_user_ips = user_activity_df['ClientIP'].tolist()\n",
    "all_user_ips = [ip for ip in all_user_ips if ip and ip != '<null>']\n",
    "# Some Office IPs have dest port appended to address\n",
    "ipv4_ips = [ip.split(\":\")[0] for ip in all_user_ips if \".\" in ip]\n",
    "ipv6_ips = [ip for ip in all_user_ips if \".\" not in ip]\n",
    "all_ips = list(set(ipv4_ips + ipv6_ips))\n",
    "\n",
    "az_net_comms_df = (\n",
    "    qry_prov\n",
    "    .Network\n",
    "    .list_azure_network_flows_by_ip(start=o365_query_times_user.start,\n",
    "                                    end=o365_query_times_user.end,\n",
    "                                    ip_address_list=all_ips)\n",
    ")\n",
    "net_default_cols = ['FlowStartTime', 'FlowEndTime', 'VMName', 'VMIPAddress', \n",
    "                'PublicIPs', 'SrcIP', 'DestIP', 'L4Protocol', 'L7Protocol',\n",
    "                'DestPort', 'FlowDirection', 'AllowedOutFlows', \n",
    "                'AllowedInFlows']\n",
    "\n",
    "# %kql -query az_net_query_byip\n",
    "# az_net_comms_df = _kql_raw_result_.to_dataframe()\n",
    "if az_net_comms_df.empty:\n",
    "    md_warn(\"No network flow data available in AzureNetworkAnalytics_CL table\"\n",
    "           + \"\\nRemainder of cell will not work.\")\n",
    "    raise ValueError(\"No network flow data available in AzureNetworkAnalytics_CL table\")\n",
    "\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    az_net_comms_df['TotalAllowedFlows'] = az_net_comms_df['AllowedOutFlows'] + az_net_comms_df['AllowedInFlows']\n",
    "    sns.catplot(x=\"L7Protocol\", y=\"TotalAllowedFlows\", col=\"FlowDirection\", data=az_net_comms_df)\n",
    "    sns.relplot(x=\"FlowStartTime\", y=\"TotalAllowedFlows\", \n",
    "                col=\"FlowDirection\", kind=\"line\", \n",
    "                hue=\"L7Protocol\", data=az_net_comms_df).set_xticklabels(rotation=50)\n",
    "\n",
    "cols = ['VMName', 'VMIPAddress', 'PublicIPs', 'SrcIP', 'DestIP', 'L4Protocol',\n",
    "        'L7Protocol', 'DestPort', 'FlowDirection', 'AllExtIPs', 'TotalAllowedFlows']\n",
    "flow_index = az_net_comms_df[cols].copy()\n",
    "def get_source_ip(row):\n",
    "    if row.FlowDirection == 'O':\n",
    "        return row.VMIPAddress if row.VMIPAddress else row.SrcIP\n",
    "    else:\n",
    "        return row.AllExtIPs if row.AllExtIPs else row.DestIP\n",
    "    \n",
    "def get_dest_ip(row):\n",
    "    if row.FlowDirection == 'O':\n",
    "        return row.AllExtIPs if row.AllExtIPs else row.DestIP\n",
    "    else:\n",
    "        return row.VMIPAddress if row.VMIPAddress else row.SrcIP\n",
    "\n",
    "flow_index['source'] = flow_index.apply(get_source_ip, axis=1)\n",
    "flow_index['target'] = flow_index.apply(get_dest_ip, axis=1)\n",
    "flow_index['value'] = flow_index['L7Protocol']\n",
    "\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    display(flow_index[['source', 'target', 'value', 'L7Protocol', \n",
    "                        'FlowDirection', 'TotalAllowedFlows']]\n",
    "            .groupby(['source', 'target', 'value', 'L7Protocol', 'FlowDirection'])\n",
    "            .sum().unstack().style.background_gradient(cmap=cm))\n",
    "\n",
    "nbdisp.display_timeline(data=az_net_comms_df.query('AllowedOutFlows > 0'),\n",
    "                         overlay_data=az_net_comms_df.query('AllowedInFlows > 0'),\n",
    "                         title='Network Flows (out=blue, in=green)',\n",
    "                         time_column='FlowStartTime',\n",
    "                         source_columns=['FlowType', 'AllExtIPs', 'L7Protocol', 'FlowDirection'],\n",
    "                         height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>[Contents](#contents)\n",
    "## Rare Combinations of Country/UserAgent/Operation Type\n",
    "The dataframe below lists combinations in the time period that had less than 3 instances. This might help you to spot relatively unusual activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:59:01.69953Z",
     "start_time": "2019-10-31T23:59:00.659363Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from msticpy.sectools.eventcluster import (dbcluster_events, \n",
    "                                           add_process_features, \n",
    "                                           char_ord_score,\n",
    "                                           token_count,\n",
    "                                           delim_count)\n",
    "\n",
    "restrict_cols = ['OfficeId', 'RecordType', 'TimeGenerated', 'Operation',\n",
    "                 'OrganizationId', 'UserType', 'UserKey', 'OfficeWorkload',\n",
    "                 'ResultStatus', 'OfficeObjectId', 'UserId', 'ClientIP','UserAgent']\n",
    "feature_office_ops = office_ops_df[restrict_cols]\n",
    "feature_office_ops = ( pd.merge(feature_office_ops, \n",
    "                                ip_locs_df, how='left', \n",
    "                                left_on='ClientIP', right_on='Address')\n",
    "                      .fillna(''))\n",
    "\n",
    "# feature_office_ops = office_ops_df.copy()\n",
    "\n",
    "feature_office_ops['country_num'] = feature_office_ops.apply(lambda x: char_ord_score(x.CountryCode) if x.CountryCode else 0, axis=1)\n",
    "feature_office_ops['ua_tokens'] = feature_office_ops.apply(lambda x: char_ord_score(x.UserAgent), axis=1)\n",
    "feature_office_ops['user_num'] = feature_office_ops.apply(lambda x: char_ord_score(x.UserId), axis=1)\n",
    "feature_office_ops['op_num'] = feature_office_ops.apply(lambda x: char_ord_score(x.Operation), axis=1)\n",
    "\n",
    "# you might need to play around with the max_cluster_distance parameter.\n",
    "# decreasing this gives more clusters.\n",
    "(clustered_ops, dbcluster, x_data) = dbcluster_events(data=feature_office_ops,\n",
    "                                                      cluster_columns=['country_num',\n",
    "                                                                       'op_num',\n",
    "                                                                       'ua_tokens'],\n",
    "                                                      time_column='TimeGenerated',\n",
    "                                                      max_cluster_distance=0.0001)\n",
    "print('Number of input events:', len(feature_office_ops))\n",
    "print('Number of clustered events:', len(clustered_ops))\n",
    "display(Markdown('#### Rarest combinations'))\n",
    "display(clustered_ops[['TimeGenerated', 'RecordType',\n",
    "                        'Operation', 'UserId', 'UserAgent', 'ClusterSize',\n",
    "                        'OfficeObjectId', 'CountryName']]\n",
    "    .query('ClusterSize <= 2')\n",
    "    .sort_values('ClusterSize', ascending=True))\n",
    "display(Markdown('#### Most common operations'))\n",
    "display((clustered_ops[['RecordType', 'Operation', 'ClusterSize']]\n",
    "    .sort_values('ClusterSize', ascending=False)\n",
    "    .head(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a></a>[Contents](#contents)\n",
    "# Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "### `msticpyconfig.yaml` configuration File\n",
    "You can configure primary and secondary TI providers and any required parameters in the `msticpyconfig.yaml` file. This is read from the current directory or you can set an environment variable (`MSTICPYCONFIG`) pointing to its location.\n",
    "\n",
    "To configure this file see the [ConfigureNotebookEnvironment notebook](https://github.com/Azure/Azure-Sentinel-Notebooks/blob/master/ConfiguringNotebookEnvironment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:59:13.369607Z",
     "start_time": "2019-10-31T23:59:13.342533Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('List of current DataFrames in Notebook')\n",
    "print('-' * 50)\n",
    "current_vars = list(locals().keys())\n",
    "for var_name in current_vars:\n",
    "    if isinstance(locals()[var_name], pd.DataFrame) and not var_name.startswith('_'):\n",
    "        print(var_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": [
     "todo"
    ]
   },
   "source": [
    "## Saving Data to Excel\n",
    "To save the contents of a pandas DataFrame to an Excel spreadsheet\n",
    "use the following syntax\n",
    "```\n",
    "writer = pd.ExcelWriter('myWorksheet.xlsx')\n",
    "my_data_frame.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "318.996px",
    "width": "320.994px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents2",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "351px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "406.193px",
    "left": "1468.4px",
    "right": "20px",
    "top": "120px",
    "width": "456.572px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
